{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999cde36-e5cd-4546-b389-ada1697dd3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 слов\n",
      "Тема #1: people see anyone good much take never thats work thing\n",
      "Тема #2: team game player hockey play last year league first new\n",
      "Тема #3: god people say jesus believe christian many even see thing\n",
      "Тема #4: people government state right law gun president armenian new going\n",
      "Тема #5: car water much good problem ive new anyone time many\n",
      "Тема #6: thing please good anyone need catholic take people ive much\n",
      "Тема #7: entry key chip bit rule number must line input build\n",
      "Тема #8: van det pit bos chi tor que buf stl nyi\n",
      "Тема #9: space launch satellite nasa earth first mission system lunar orbit\n",
      "Тема #10: file window program key available using system image data information\n",
      "Тема #11: wire ground good need circuit much problem many time usually\n",
      "Тема #12: anyone problem good thanks please see two using take need\n",
      "Тема #13: do anyone san two people much time good year ive\n",
      "Тема #14: good new anyone excellent annual comic thanks cover please rider\n",
      "Тема #15: medical health child number center research patient study people new\n",
      "Тема #16: didnt people going went said time even see first told\n",
      "Тема #17: people anyone time much even number problem please jew many\n",
      "Тема #18: drive card hard disk driver controller problem scsi need mac\n",
      "Тема #19: much people anyone even believe something really point good question\n",
      "Тема #20: anyone good new need time please looking problem back look\n",
      "\n",
      " Исходные темы\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "documents = newsgroups_train.data\n",
    "target_names = newsgroups_train.target_names\n",
    "\n",
    "def func(text):\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\'', '', text) \n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    t = text.lower().split()\n",
    "    \n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    delete = {'may','also','do', 'used','use','want','would', 'get', 'like', 'one', 'know', 'dont', 'could', 'think', 'make'}\n",
    "    all = english_stopwords.union(delete)\n",
    "    \n",
    "    t = [\n",
    "        lemmatizer.lemmatize(word) \n",
    "        for word in t \n",
    "        if word.isalpha() and word not in all and len(word) > 2\n",
    "    ]\n",
    "    return t\n",
    "\n",
    "new_doc = [func(doc) for doc in documents]\n",
    "\n",
    "dictionary = Dictionary(new_doc)\n",
    "\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.85)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in new_doc]\n",
    "\n",
    "n1 = 20\n",
    "n2 = 100\n",
    "n3 = 10\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    num_topics=n1,\n",
    "    id2word=dictionary,\n",
    "    alpha=1.0,\n",
    "    eta=1.0,\n",
    "    iterations=n2,\n",
    "    random_state=42,\n",
    "    eval_every=None\n",
    ")\n",
    "\n",
    "print(\"Топ-10 слов\")\n",
    "\n",
    "for k in range(n1):\n",
    "    terms = lda_model.get_topic_terms(k, topn=n3)\n",
    "    words = [dictionary[term_id] for term_id, weight in terms]\n",
    "    print(f\"Тема #{k+1}: {' '.join(words)}\")\n",
    "\n",
    "print(\"\\n Исходные темы\")\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ac51d-9a20-4f70-bc70-22090fc31b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
